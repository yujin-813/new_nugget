import logging
import pandas as pd
import os
import openai
import json
from db_manager import DBManager

class FileAnalysisEngine:
    def __init__(self):
        pass

    def process(self, question, file_path, conversation_id=None, prev_source=None):
        logging.info(f"ğŸ“ [File Engine] Analyzing: {file_path}")
        if not file_path or not os.path.exists(file_path):
             return {"message": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "status": "error"}
             
        try:
            # 1. Load Data
            df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)
            
            # 2. Context / State Management
            state = {}
            if conversation_id:
                # [Phase 5] Restore last intent if follow-up
                state = DBManager.load_last_state(conversation_id, "file") or {}
                
            # 3. Analyze Query (Level 1-3 Strategy)
            result_df, message, intent = self._analyze_query(df, question, state)
            
            # 4. Transform for Visualization
            plot_data = self._transform_to_plot_data(result_df, intent)
            
            # 5. Save State
            if result_df is not None and conversation_id:
                # [Phase 5] Save Intent for Follow-up
                state["last_intent"] = intent
                DBManager.save_success_state(conversation_id, "file", state)

            return {
                "message": message,
                "status": "ok",
                "plot_data": plot_data,
                "raw_data": result_df.head(50).where(pd.notnull(result_df), None).to_dict(orient='records') if result_df is not None else []
            }
            
        except Exception as e:
            logging.error(f"[File Engine Error] {e}")
            return {"message": f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}", "status": "error"}

    def _analyze_query(self, df, question, state):
        # [Phase 5] 3-Level Processing Strategy
        intent = self._detect_intent(question, state)
        
        # 1. Level 1 & 2: Skip LLM (Exploration & Aggregation)
        if intent["type"] in ["schema", "preview", "overview", "groupby", "aggregate", "distribution", "filter"]:
            result_df = self._execute_aggregation(df, intent)
            
            if intent["type"] == "schema":
                msg = "ìš”ì²­í•˜ì‹  íŒŒì¼ì˜ êµ¬ì¡°(ì»¬ëŸ¼ ì •ë³´)ì…ë‹ˆë‹¤."
            elif intent["type"] == "preview":
                msg = f"íŒŒì¼ì˜ ìƒìœ„ {len(result_df)}í–‰ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤."
            elif intent["type"] == "overview":
                msg = f"íŒŒì¼ ì „ì²´ ê°œìš”: ì´ {len(df)}í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼"
            elif intent["type"] in ["groupby", "distribution"]:
                msg = f"ìš”ì²­í•˜ì‹  '{intent.get('keywords', ['ê·¸ë£¹'])[0]}' ê¸°ì¤€ ì§‘ê³„ ê²°ê³¼ì…ë‹ˆë‹¤."
            elif intent["type"] == "aggregate":
                if len(result_df) == 1 and result_df.shape[1] == 1:
                     val = result_df.iloc[0, 0]
                     msg = f"ê³„ì‚° ê²°ê³¼: {val}"
                else:
                     msg = "ìš”ì²­í•˜ì‹  ì§‘ê³„ ê²°ê³¼ì…ë‹ˆë‹¤."
            else:
                msg = "ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
            
            return result_df, msg, intent 

        # 2. Level 3: Insight (LLM Required)
        elif intent["type"] == "insight":
            logging.info("[FileEngine] Intent is Insight. Calling LLM.")
            # Insight logic requires schema and data summary
            result_df = df # Default to full df for context
            insight = self._generate_insight(df, result_df, question)
            return result_df, insight, intent
            
        # Default Fallback
        logging.info("[FileEngine] Intent Unclear or Default. Calling LLM for safety.")
        insight = self._generate_insight(df, df, question)
        return df, insight, intent

    def _detect_intent(self, question, state):
        q_lower = question.lower()
        intent = {"type": "insight", "keywords": []}
        
        # [Phase 5] 3-Level Intent Detection
        
        # Level 1: Exploration (íƒìƒ‰)
        if any(kw in q_lower for kw in ['êµ¬ì¡°', 'ì»¬ëŸ¼', 'ì—´', 'schema', 'structure']):
             intent["type"] = "schema"
        elif any(kw in q_lower for kw in ['í–‰', 'ìƒ˜í”Œ', 'ì˜ˆì‹œ', 'preview', 'sample', 'ë³´ì—¬ì¤˜', 'raw data']):
             intent["type"] = "preview"
        elif any(kw in q_lower for kw in ['ê°œìš”', 'ìš”ì•½', 'overview', 'summary', 'ì „ì²´']):
             intent["type"] = "overview"
             
        # Level 2: Aggregation (ì§‘ê³„)
        elif any(kw in q_lower for kw in ['ë³„', 'íƒ€ì…ë³„', 'ì¢…ë¥˜ë³„', 'ì¹´í…Œê³ ë¦¬ë³„', 'by ', 'ê·¸ë£¹']):
            intent["type"] = "groupby"
            intent["keywords"] = ["ë³„"]
        elif any(kw in q_lower for kw in ['í‰ê· ', 'average', 'avg', 'mean']):
            intent["type"] = "aggregate"
            intent["keywords"] = ["í‰ê· "]
        elif any(kw in q_lower for kw in ['í•©ê³„', 'ì´', 'sum', 'total']):
            intent["type"] = "aggregate"
            intent["keywords"] = ["í•©ê³„"]
        elif any(kw in q_lower for kw in ['ê°œìˆ˜', 'count', 'ëª‡ ê°œ']):
            intent["type"] = "aggregate"
            intent["keywords"] = ["ê°œìˆ˜"]
            
        # Follow-up detection (Level 3 or Level 2 context)
        elif any(kw in q_lower for kw in ['ì‘', 'ê·¸ë˜', 'ë³´ì—¬ì¤˜', 'ì„¤ëª…í•´ì¤˜']):
            if state.get("last_intent"):
                intent = state["last_intent"]
                intent["is_followup"] = True
            else:
                intent["type"] = "insight"
                
        return intent

    def _execute_aggregation(self, df, intent):
        # Simplified aggregation for restoration
        if intent["type"] == "schema":
            return pd.DataFrame({"Column": df.columns, "Type": df.dtypes.astype(str)})
        elif intent["type"] == "preview":
            return df.head(10)
        elif intent["type"] == "overview":
            return df.describe(include='all')
        # Placeholder for more complex groupby/agg
        return df.head(10)

    def _transform_to_plot_data(self, df, intent):
        if df is None or df.empty or intent["type"] in ["schema", "preview"]:
            return {"type": None, "labels": [], "series": []}
        # Simple bar for now
        return {"type": "bar", "labels": [], "series": []}

    def _generate_insight(self, df, result_df, question):
        schema = df.columns.tolist()
        summary = df.describe().to_json()
        
        prompt = f"""
        Analyze this file data.
        Question: {question}
        Schema: {schema}
        Summary: {summary}
        
        Provide a concise Korean insight based on the data.
        """
        try:
            res = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            return res['choices'][0]['message']['content'].strip()
        except:
            return "íŒŒì¼ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

file_engine = FileAnalysisEngine()
